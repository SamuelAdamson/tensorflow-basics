{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion MNIST Dataset\n",
    "## Author: Samuel Adamson\n",
    "### Tensorflow, Tensorflow Datasets, Numpy, MatPlotLib\n",
    "### Last Edited 11/27/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Set logging for errors only\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Fashion MNIST data from Tensorflow Datasets.\n",
    "Training Data: 60,000 Entries\n",
    "Testing Data: 10,000 Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training / testing datasets ( Fashion MNIST )\n",
    "# Return Type: Tuple\n",
    "# @RETURN: ( [ training data, testing data ], class names, num_training, num_testing )\n",
    "def get_data():\n",
    "    # Disable progress bar on datasets\n",
    "    tfds.disable_progress_bar()\n",
    "\n",
    "    # Get data / metadata, separate out training and testing data\n",
    "    dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "    training, testing = dataset['train'], dataset['test']\n",
    "    # Curate Data\n",
    "    data, class_names, num_training, num_testing = get_data()\n",
    "    data = preprocess(data)\n",
    "    # Parse out class names\n",
    "    class_names = metadata.features['label'].names\n",
    "    \n",
    "    # Data for training\n",
    "    num_training = metadata.splits['train'].num_examples # Number of training examples\n",
    "    num_testing = metadata.splits['test'].num_examples  # Number of testing examples\n",
    "\n",
    "    return ([training, testing], class_names, num_training, num_testing)\n",
    "\n",
    "# Preprocess data for training\n",
    "# Return Type: List\n",
    "# @RETURN: [ training data, testing data, class names ]\n",
    "def preprocess(data):\n",
    "\n",
    "    # Normalize data\n",
    "    # Scale data from 0 - 255 to 0 - 1\n",
    "    def normalize(images, labels):\n",
    "        # Divide by 255\n",
    "        images = tf.cast(images, tf.float32) / 255\n",
    "        return images, labels\n",
    "\n",
    "    # Normalize Training and Testing Data\n",
    "    data[0] = data[0].map(normalize)\n",
    "    data[1] = data[1].map(normalize)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Curate Data\n",
    "data, class_names, num_training, num_testing = get_data()\n",
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Data -- Reshape and show images\n",
    "# Return Type: None\n",
    "# @RETURN: None\n",
    "def example_data(sub_data):\n",
    "    # Format plot figure size\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    # Iterate through subsidiary data\n",
    "    for i, (image, label) in enumerate(sub_data):\n",
    "        # Reshape Image\n",
    "        image = image.numpy().reshape((28,28))\n",
    "        # Plot\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_names[label])\n",
    "\n",
    "    # # Save plot\n",
    "    # plt.savefig('./figs/example_data.png')\n",
    "    # Show Plot\n",
    "    plt.show()\n",
    "\n",
    "# Show example data \n",
    "example_data(data[1].take(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model, Train Model, Evaluate accuracy of model after training\n",
    "Model contains three layers:\n",
    "\n",
    "    *Input Layer* - Transforms 28x28 2d array to 784 1d array\n",
    "    *Hidden Layer* - Densely connect layer of 128 nodes\n",
    "    *Output Layer* - 10 Node softmax layer, each node represents one class of clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Train Model:\n",
    "#   Input Layer: Flatten 28 by 28 images, 784 nodes\n",
    "#   Hidden Layer: Densely connected, 128 nodes\n",
    "#   Output Layer: Softmax 10 nodes 10 classes, sum of all 10 nodes = 1\n",
    "# Return Type: Keras Model\n",
    "# @RETURN: ( Model )\n",
    "def ct_model(dataset, num_training):\n",
    "    # Define model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # Configure Model for training\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Training Settings, cache data, shuffle data, sort into batch sizes\n",
    "    batch_size = 32\n",
    "    dataset = dataset.cache().repeat().shuffle(num_training).batch(batch_size)\n",
    "    # Conduct training\n",
    "    #   Max epochs 5\n",
    "    model.fit(dataset, epochs=5)\n",
    "\n",
    "    # Save model upon completion\n",
    "    model.save('./fashion_mnist_classification')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Evaluate accuracy\n",
    "# Return Type: None\n",
    "# @RETURN: None\n",
    "def eval_accuracy(model, dataset, num_testing):\n",
    "    # Configure data\n",
    "    batch_size = 32\n",
    "    dataset = dataset.cache().batch(batch_size)\n",
    "\n",
    "    # Evaluate\n",
    "    loss, accuracy = model.evaluate(dataset, steps=math.ceil(num_testing/batch_size))\n",
    "    print('Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "# Create and train model\n",
    "model = ct_model(data[0], num_training)\n",
    "# Test Accuracy using testing data\n",
    "eval_accuracy(model, data[1], num_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image with green label == correct prediction, red label == incorrect prediction\n",
    "# Return Type: None\n",
    "# @RETURN: None\n",
    "def plot_image(index, predictions, actual_labels, images, class_names):\n",
    "    # Store prediction, correct label, and corresponding image at index\n",
    "    prediction, actual_label, image = predictions[index], actual_labels[index], images[index]\n",
    "\n",
    "    # Configure plot\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # Display data as image\n",
    "    plt.imshow(image[...,0], cmap=plt.cm.binary)\n",
    "\n",
    "    # Predicted class, highest probability\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    # Store color green = correct, red = incorrect\n",
    "    color = 'red'\n",
    "    if predicted_label == actual_label:\n",
    "        color = 'green'\n",
    "\n",
    "    # Plot labels\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(prediction),\n",
    "                                         class_names[actual_label]),\n",
    "                                         color=color)\n",
    "\n",
    "\n",
    "# Plot calculated chance for each class in bar chart\n",
    "# Return Type: None\n",
    "# @RETURN: None\n",
    "def plot_class_values(index, predictions, actual_labels):\n",
    "    # Store prediction and correct label at index\n",
    "    prediction, actual_label = predictions[index], actual_labels[index]\n",
    "\n",
    "    # Configure plot\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # Create plot of predictions\n",
    "    predictions_plot = plt.bar(range(10), predictions, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions)\n",
    "\n",
    "    # Color each prediction based on correctness\n",
    "    predictions_plot[predicted_label].set_color('red')\n",
    "    predictions_plot[actual_label].set_color('blue')\n",
    "\n",
    "\n",
    "# Plot predictions for first n * m images in testing dataset\n",
    "# Return Type: None\n",
    "# @RETURN: None\n",
    "def plot_predictions(n, m, dataset, model, class_names):\n",
    "    # Get elements from dataset\n",
    "    for images, labels in dataset.take(1):\n",
    "        images = images.numpy()\n",
    "        labels = labels.numpy()\n",
    "\n",
    "        # Store predictions\n",
    "        predictions = model.predict(images)\n",
    "\n",
    "\n",
    "    # Number of images n * m array\n",
    "    num_images = n*m\n",
    "    # Plot images and predictions\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(n, 2*m, 2*i+1)\n",
    "        plot_image(i, predictions, labels, images)\n",
    "        plt.subplot(n, 2*m, 2*i+2)\n",
    "        plot_class_values(i, predictions, labels)\n",
    "\n",
    "    # Show Plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot 15 Predictions\n",
    "plot_predictions(5, 3, data[1], class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
