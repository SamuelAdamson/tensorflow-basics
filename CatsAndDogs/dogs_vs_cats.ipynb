{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Color Images - Dogs, Cats\n",
    "### Author: Samuel Adamson\n",
    "### Tensorflow, Google ML Datasets, Numpy, MatPlotLib\n",
    "### Last Edited 01/01/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set logging for errors only\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# Make directories\n",
    "# !mkdir figs\n",
    "# !mkdir model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Data from Google ML Dataset <br>\n",
    "Unzip Data <br>\n",
    "Store directories with different data types: <br>\n",
    "&emsp; Training Data <br>\n",
    "&emsp; Validation Data <br>\n",
    "<br>\n",
    "Evaluate data - Number of data points in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data url for download\n",
    "DATA_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "# Download, store in directory, extract from .zip\n",
    "dir = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=DATA_URL, extract=True)\n",
    "\n",
    "# Store path to each type of data (training/validation)\n",
    "data_dir = os.path.join(os.path.dirname(dir), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "# Store path to each type of image classification\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "valid_cats_dir = os.path.join(valid_dir, 'cats')\n",
    "valid_dogs_dir = os.path.join(valid_dir, 'dogs')\n",
    "\n",
    "\n",
    "# Number of validation images\n",
    "num_val = len(os.listdir(valid_cats_dir)) + len(os.listdir(valid_dogs_dir))\n",
    "print(f'Number of validation images: {num_val}')\n",
    "\n",
    "# Number of training images\n",
    "num_train = len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir))\n",
    "print(f'Number of training images: {num_train}')\n",
    "print('---')\n",
    "\n",
    "# Number of training / validation cats\n",
    "num_train_cats = len(os.listdir(train_cats_dir))\n",
    "num_valid_cats = len(os.listdir(valid_cats_dir))\n",
    "tot_cats = num_train_cats + num_valid_cats\n",
    "print(f'Number of training cat images: {num_train_cats}')\n",
    "print(f'Number of validation cat images: {num_valid_cats}')\n",
    "print(f'Total number of cat images: {tot_cats}')\n",
    "print('---')\n",
    "\n",
    "# Number of training / validation dogs\n",
    "num_train_dogs = len(os.listdir(train_dogs_dir))\n",
    "num_valid_dogs = len(os.listdir(valid_dogs_dir))\n",
    "tot_dogs = num_train_dogs + num_valid_dogs\n",
    "print(f'Number of training dog images: {num_train_dogs}')\n",
    "print(f'Number of validation dog images: {num_valid_dogs}')\n",
    "print(f'Total number of dog images: {tot_dogs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data / Prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size -- Number of images to process before adjusting model weights\n",
    "BATCH_SIZE = 100\n",
    "# Image Size -- height and width\n",
    "IMG_SIZE = 150\n",
    "\n",
    "# Image generators for training and validation sets\n",
    "train_image_gen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "valid_image_gen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Flow images from directory into image generators\n",
    "train_image_gen = train_image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=train_dir,\n",
    "                                                      shuffle=True, target_size=(IMG_SIZE, IMG_SIZE), \n",
    "                                                      class_mode='binary')\n",
    "\n",
    "valid_image_gen = valid_image_gen.flow_from_directory(batch_size=BATCH_SIZE, directory=valid_dir,\n",
    "                                                      shuffle=True, target_size=(IMG_SIZE, IMG_SIZE), \n",
    "                                                      class_mode='binary')                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get batch of images and labels from training set\n",
    "sample_images, sample_labels = next(train_image_gen)\n",
    "\n",
    "# Plot images and labels\n",
    "# @PARAMS: Training data batch - images, labels\n",
    "# @RETURN: None\n",
    "def plotData(images, labels):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    # Iterate through images\n",
    "    for i, img in enumerate(images):\n",
    "        # Plot Image\n",
    "        plt.subplot(5,5,i+1)\n",
    "        # Hide ticks\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        # Image and corresponding label\n",
    "        plt.imshow(img, cmap=plt.cm.binary)\n",
    "        plt.xlabel(labels[i])\n",
    "\n",
    "    # Show pot\n",
    "    plt.show()\n",
    "    plt.savefig('./figs/example_data.png')\n",
    "\n",
    "# Plot some test images\n",
    "plotData(sample_images[:25], sample_labels[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model -- 4 Convolution Blocks 1 Densely Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Block 4\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "EPOCH_COUNT = 100\n",
    "# Conduct Training\n",
    "history = model.fit_generator(\n",
    "    train_image_gen,\n",
    "    steps_per_epoch=int(np.ceil(num_train / float(BATCH_SIZE))),\n",
    "    epochs=EPOCH_COUNT,\n",
    "    validation_data=valid_image_gen,\n",
    "    validation_steps=int(np.ceil(num_val / float(BATCH_SIZE)))\n",
    ")\n",
    "\n",
    "# Store Accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Store Loss\n",
    "loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Range of epochs\n",
    "epochs_range = range(EPOCH_COUNT)\n",
    "\n",
    "# Plot configuration -- Accuracy\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "# Plot configuration -- Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss')\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('./figs/training.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0b20b1a19b167b80ac33a2e48a60a135c96ac935154df81504b081f0383a4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
